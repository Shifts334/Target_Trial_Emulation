{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TargetTrialEmulator:\n",
    "    def __init__(self, estimand=\"ITT\"):\n",
    "        self.estimand = estimand\n",
    "        self.weights = None\n",
    "        self.model = None\n",
    "        self.expanded_data = None\n",
    "        self.data = None\n",
    "        self.cluster_models = {}  # For cluster-specific models\n",
    "\n",
    "    def prepare_data(self, data_path):\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.data['age_s'] = self.data['age'] + self.data['period']/12\n",
    "        return self\n",
    "\n",
    "    def cluster_patients(self, n_clusters=3):\n",
    "        \"\"\"Cluster patients based on baseline characteristics.\"\"\"\n",
    "        baseline = self.data.groupby('id').first()[['age', 'x1', 'x2', 'x3']]\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        clusters = kmeans.fit_predict(baseline)\n",
    "        self.data['cluster'] = self.data['id'].map(\n",
    "            pd.Series(clusters, index=baseline.index))\n",
    "        return self\n",
    "\n",
    "    def calculate_weights(self):\n",
    "        if self.estimand == \"PP\":\n",
    "            switch_num = LogisticRegression()\n",
    "            switch_num.fit(self.data[['age']], self.data['treatment'])\n",
    "            numer = switch_num.predict_proba(self.data[['age']])[:,1]\n",
    "            \n",
    "            switch_den = LogisticRegression()\n",
    "            switch_den.fit(self.data[['age', 'x1', 'x3']], self.data['treatment'])\n",
    "            denom = switch_den.predict_proba(self.data[['age', 'x1', 'x3']])[:,1]\n",
    "            switch_weights = numer / denom\n",
    "        else:\n",
    "            switch_weights = np.ones(len(self.data))\n",
    "        \n",
    "        censor_model = LogisticRegression()\n",
    "        censor_model.fit(self.data[['x2', 'x1']], self.data['censored'])\n",
    "        censor_weights = 1 / censor_model.predict_proba(self.data[['x2', 'x1']])[:,0]\n",
    "        self.weights = switch_weights * censor_weights\n",
    "        return self\n",
    "\n",
    "    def expand_trials(self):\n",
    "        expanded = []\n",
    "        for period in self.data['period'].unique():\n",
    "            period_data = self.data[self.data['period'] == period].copy()\n",
    "            period_data['trial_period'] = period\n",
    "            expanded.append(period_data)\n",
    "        self.expanded_data = pd.concat(expanded)\n",
    "        return self\n",
    "\n",
    "    def fit_msm(self):\n",
    "        q99 = np.quantile(self.weights, 0.99)\n",
    "        self.expanded_data['weights'] = np.minimum(self.weights, q99)\n",
    "        self.model = CoxPHFitter()\n",
    "        self.model.fit(\n",
    "            self.expanded_data[['treatment', 'x2', 'period', 'outcome', 'weights']],\n",
    "            duration_col='period',\n",
    "            event_col='outcome',\n",
    "            weights_col='weights',\n",
    "            robust=True\n",
    "        )\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3351636683.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 42\u001b[1;36m\u001b[0m\n\u001b[1;33m    times=np.linspace(0, max_period, 50)\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. Load data and cluster patients\n",
    "    emulator = TargetTrialEmulator(estimand=\"ITT\")\n",
    "    emulator.prepare_data(\"data_censored.csv\")\n",
    "    emulator.cluster_patients(n_clusters=3)\n",
    "    \n",
    "    # 2. Analyze each cluster separately\n",
    "    cluster_results = {}\n",
    "    for cluster in sorted(emulator.data['cluster'].unique()):\n",
    "        print(f\"\\n=== Analyzing Cluster {cluster} ===\")\n",
    "        \n",
    "        # Subset cluster data\n",
    "        cluster_data = emulator.data[emulator.data['cluster'] == cluster].copy()\n",
    "        \n",
    "        # Create new emulator for cluster\n",
    "        cluster_emulator = TargetTrialEmulator(estimand=\"ITT\")\n",
    "        cluster_emulator.data = cluster_data\n",
    "        cluster_emulator.calculate_weights()\n",
    "        cluster_emulator.expand_trials()\n",
    "        cluster_emulator.fit_msm()\n",
    "        \n",
    "        # Store results\n",
    "        cluster_results[cluster] = {\n",
    "            'model': cluster_emulator.model,\n",
    "            'data': cluster_emulator.expanded_data\n",
    "        }\n",
    "        \n",
    "        # Save cluster data\n",
    "        cluster_emulator.expanded_data.to_csv(f\"cluster_{cluster}_data.csv\", index=False)\n",
    "\n",
    "    # 3. Generate cluster survival curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    max_period = emulator.data['period'].max()\n",
    "    \n",
    "    for cluster, result in cluster_results.items():\n",
    "        # Get baseline prediction data (first observation in cluster)\n",
    "        baseline_data = result['data'].query(\"period == 0\").iloc[:1]\n",
    "        \n",
    "        # Generate survival predictions\n",
    "        survival = result['model'].predict_survival_function(\n",
    "            baseline_data, \n",
    "            times=np.linspace(0, max_period, 50))\n",
    "        \n",
    "        plt.plot(survival.T, label=f'Cluster {cluster}', linewidth=2)\n",
    "\n",
    "    plt.title(\"Survival Probability by Patient Cluster\", fontsize=14)\n",
    "    plt.xlabel(\"Time Periods\", fontsize=12)\n",
    "    plt.ylabel(\"Survival Probability\", fontsize=12)\n",
    "    plt.ylim(0.5, 1.05)\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"cluster_survival_curves.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Print cluster summaries\n",
    "    print(\"\\nCluster-wise Treatment Effects:\")\n",
    "    for cluster, result in cluster_results.items():\n",
    "        print(f\"\\nCluster {cluster}:\")\n",
    "        print(result['model'].summary.loc['treatment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
